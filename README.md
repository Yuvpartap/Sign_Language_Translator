# Sign_Language_Translator
Sign language is a set of gestures that deaf people use to communicate. Unfortunately, 
normal people donâ€™t understand it, which creates a communication gap that needs to 
be filled. In this work, we present a computer vision system with neural network 
architectures. The architecture is a CNN followed by a Long Short-Term Memory 
(LSTM) for extracting both spatial and temporal features. The two models achieved an 
accuracy of 90% and 72%, respectively.
